{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Data Science\n",
    "## Homework 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Student Name: Yuhan Liu\n",
    "\n",
    "Student Netid: yl7576\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1: Case study (5 Points)\n",
    "- Read [this article](http://www.nytimes.com/2012/02/19/magazine/shopping-habits.html) in the New York Times.\n",
    "- Use what we've learned in class and from the book to describe how one could set Target's problem up as a predictive modeling problem, such that they could have gotten the results that they did.  Formulate your solution as a proposed plan using our data science terminology.  Include all the aspects of the data mining process, and be sure to include the motivation for predictive modeling and give a sketch of a solution.  Be precise but concise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:\n",
    "\n",
    "In the case, Target wants to attract more customers, but normally people will have fixed shopping habits which are hard to change. Therefore, Target wants to capture some unique moments in consumers’ lives when their shopping habits become flexible. For example, expecting a baby, graduating from colleage, or moving to a new city, etc. \n",
    "\n",
    "Here, Target wants to know whether a consumer is pregnant or not. To build such a pregnancy-prediction model, the main resource they have is historical shopping data. Therefore, they can first use Target’s baby-shower registry to know the due date of a pregnant woman and observe how shopping habits changed as a woman approached her due date, which can be the train test data for the prediction model. For example, at the beginning of pregnancy, women customers may start to buy vitamins and when approaching to due date, they will buy baby products. In this way, when Target collects a woman’s shopping history, if she buys a vitamin specifically for pregnant women, they can predict that the customer may just get pregnant and start to send advertisement or coupon according to different pregnancy stage. \n",
    "\n",
    "Also, it may seem to be cursory for Target to determine pregnancy by only one-time purchase. They should collect more data such as one’s browsing history on the website. If one customer fits most characteristics of pregnancy, the model can give her a high score and start to market some related products. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2: Exploring data in the command line (4 Points)\n",
    "For this part we will be using the data file located in `\"data/advertising_events.csv\"`. This file consists of records that pertain to some online advertising events on a given day. There are 4 comma separated columns in this order: `userid`, `timestamp`, `domain`, and `action`. These fields are of type `int`, `int`, `string`, and `int` respectively. Answer the following questions using Linux/Unix bash commands. All questions can be answered in one line (sometimes, with pipes)! Some questions will have many possible solutions. Don't forget that in IPython notebooks you must prefix all bash commands with an exclamation point, i.e. `\"!command arguments\"`.\n",
    "\n",
    "[Hints: You can experiment with whatever you want in the notebook and then delete things to construct your answer later.  You can also use a bash shell (i.e., EC2 or a Mac terminal) and then just paste your answers here. Recall that once you enter the \"!\" then filename completion should work.]\n",
    "\n",
    "[Here](https://opensource.com/article/17/2/command-line-tools-data-analysis-linux) is a good linux command line reference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1\\. How many records (lines) are in this file? (look up 'wc' command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   10341 /Users/yuhanliu/Downloads/advertising_events.csv\r\n"
     ]
    }
   ],
   "source": [
    "!wc -l data/advertising_events.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2\\. How many unique users are in this file? (hint: consider the 'cut' command and use pipe operator '|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     732\r\n"
     ]
    }
   ],
   "source": [
    "!cut -d',' -f1 data/advertising_events.csv | sort -u | wc -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3\\. Rank all domains by the number of visits they received in descending order. (hint: consider the 'cut', 'uniq' and 'sort' commands and the pipe operator)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3114 google.com\r\n",
      "2092 facebook.com\r\n",
      "1036 youtube.com\r\n",
      "1034 yahoo.com\r\n",
      "1022 baidu.com\r\n",
      " 513 wikipedia.org\r\n",
      " 511 amazon.com\r\n",
      " 382 qq.com\r\n",
      " 321 twitter.com\r\n",
      " 316 taobao.com\r\n"
     ]
    }
   ],
   "source": [
    "!cut -d \",\" -f3 data/advertising_events.csv | sort | uniq -c | sort -nr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4\\. List all records for the user with user id 37. (hint: this can be done using 'grep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37,648061658,google.com,0\r\n",
      "37,642479972,google.com,2\r\n",
      "37,644493341,facebook.com,2\r\n",
      "37,654941318,facebook.com,1\r\n",
      "37,649979874,baidu.com,1\r\n",
      "37,653061949,yahoo.com,1\r\n",
      "37,655020469,google.com,3\r\n",
      "37,640878012,amazon.com,0\r\n",
      "37,659864136,youtube.com,1\r\n",
      "37,640361378,yahoo.com,1\r\n",
      "37,653862134,facebook.com,0\r\n",
      "37,648828970,youtube.com,0\r\n"
     ]
    }
   ],
   "source": [
    "!grep ^37, data/advertising_events.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3: Dealing with data Pythonically (16 Points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1\\. (1 Point) Download the data set `\"data/ads_dataset.tsv\"` and load it into a Python Pandas data frame called `ads`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>isbuyer</th>\n",
       "      <th>buy_freq</th>\n",
       "      <th>visit_freq</th>\n",
       "      <th>buy_interval</th>\n",
       "      <th>sv_interval</th>\n",
       "      <th>expected_time_buy</th>\n",
       "      <th>expected_time_visit</th>\n",
       "      <th>last_buy</th>\n",
       "      <th>last_visit</th>\n",
       "      <th>multiple_buy</th>\n",
       "      <th>multiple_visit</th>\n",
       "      <th>uniq_urls</th>\n",
       "      <th>num_checkins</th>\n",
       "      <th>y_buy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>106</td>\n",
       "      <td>106</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>169</td>\n",
       "      <td>2130</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>72</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>154</td>\n",
       "      <td>1100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>539</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-101.149300</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>103</td>\n",
       "      <td>362</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.979170</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.621240</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>168</td>\n",
       "      <td>2080</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.041667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.916713</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>132</td>\n",
       "      <td>556</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>180</td>\n",
       "      <td>180</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>71</td>\n",
       "      <td>400</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>185</td>\n",
       "      <td>185</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>77</td>\n",
       "      <td>401</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>54584 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     isbuyer  buy_freq  visit_freq  buy_interval  sv_interval  \\\n",
       "NaN        0       NaN           1           0.0     0.000000   \n",
       "NaN        0       NaN           1           0.0     0.000000   \n",
       "NaN        0       NaN           1           0.0     0.000000   \n",
       "NaN        0       NaN           1           0.0     0.000000   \n",
       "NaN        0       NaN           2           0.0     0.500000   \n",
       "..       ...       ...         ...           ...          ...   \n",
       "NaN        0       NaN           3           0.0    30.979170   \n",
       "NaN        0       NaN           2           0.0     1.041667   \n",
       "NaN        0       NaN           1           0.0     0.000000   \n",
       "NaN        0       NaN           1           0.0     0.000000   \n",
       "NaN        0       NaN           1           0.0     0.000000   \n",
       "\n",
       "     expected_time_buy  expected_time_visit  last_buy  last_visit  \\\n",
       "NaN                0.0             0.000000       106         106   \n",
       "NaN                0.0             0.000000        72          72   \n",
       "NaN                0.0             0.000000         5           5   \n",
       "NaN                0.0             0.000000         6           6   \n",
       "NaN                0.0          -101.149300       101         101   \n",
       "..                 ...                  ...       ...         ...   \n",
       "NaN                0.0            12.621240         8           8   \n",
       "NaN                0.0            -0.916713         1           1   \n",
       "NaN                0.0             0.000000        20          20   \n",
       "NaN                0.0             0.000000       180         180   \n",
       "NaN                0.0             0.000000       185         185   \n",
       "\n",
       "     multiple_buy  multiple_visit  uniq_urls  num_checkins  y_buy  \n",
       "NaN             0               0        169          2130      0  \n",
       "NaN             0               0        154          1100      0  \n",
       "NaN             0               0          4            12      0  \n",
       "NaN             0               0        150           539      0  \n",
       "NaN             0               1        103           362      0  \n",
       "..            ...             ...        ...           ...    ...  \n",
       "NaN             0               1        168          2080      0  \n",
       "NaN             0               1          1            15      0  \n",
       "NaN             0               0        132           556      0  \n",
       "NaN             0               0         71           400      0  \n",
       "NaN             0               0         77           401      0  \n",
       "\n",
       "[54584 rows x 14 columns]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Place your code here\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "ads = pd.read_csv(\"ads_dataset.tsv\",sep = '\\t')\n",
    "ads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2\\. (4 Points) Write a Python function called `getDfSummary()` that does the following:\n",
    "- Takes as input a data frame\n",
    "- For each variable in the data frame calculates the following features:\n",
    "  - `number_nan` to count the number of missing not-a-number values\n",
    "  - Ignoring missing, NA, and Null values:\n",
    "    - `number_distinct` to count the number of distinct values a variable can take on\n",
    "    - `mean`, `max`, `min`, `std` (standard deviation), and `25%`, `50%`, `75%` to correspond to the appropriate percentiles\n",
    "- All of these new features should be loaded in a new data frame. Each row of the data frame should be a variable from the input data frame, and the columns should be the new summary features.\n",
    "- Returns this new data frame containing all of the summary information\n",
    "\n",
    "Hint: The pandas `describe()` method returns a useful series of values that can be used here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDfSummary(input_data):\n",
    "    output_data = input_data.describe().transpose()\n",
    "    output_data[\"number_distinct\"] = [ads[i].dropna().nunique() for i in output_data.index.values]\n",
    "    output_data['number_nan'] = [ads[i].isna().sum() for i in output_data.index.values ]\n",
    "    return output_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3\\. How long does it take for your `getDfSummary()` function to work on your `ads` data frame? Show us the results below.\n",
    "\n",
    "Hint: `use %timeit`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56.1 ms ± 1.91 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit getDfSummary(ads)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4\\. (2 Points) Using the results returned from `getDfSummary()`, which fields, if any, contain missing `NaN` values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['buy_freq'], dtype=object)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = getDfSummary(ads)\n",
    "result.loc[result['number_nan'] > 0].index.values\n",
    "# buy_freq contains missing NaN values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5\\. (4 Points) For the fields with missing values, does it look like the data is missing at random? Are there any other fields that correlate perfectly, or make it more likely that the data is missing? If missing, what should the data value be? Don't just show code here. Please explain your answer.[Edit this to ask for more details on why they are 0]\n",
    "\n",
    "Hint: create another data frame that has just the records with a missing value. Get a summary of this data frame using `getDfSummary()` and compare the differences. Do some feature distributions change dramatically?\n",
    "\n",
    "\n",
    "Answer: the data is not missing at random. All NA data come from buy_freq column and we should set the data value to be 0 because the customer did not purchase anything. That is why features related to purchase process, such as isbuyer, expected_time_buy, and multiple_buy, are all zero in the summary table. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "      <th>number_distinct</th>\n",
       "      <th>number_nan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>isbuyer</th>\n",
       "      <td>52257.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>buy_freq</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>52257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>visit_freq</th>\n",
       "      <td>52257.0</td>\n",
       "      <td>1.651549</td>\n",
       "      <td>2.147955</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>84.00000</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>buy_interval</th>\n",
       "      <td>52257.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>295</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sv_interval</th>\n",
       "      <td>52257.0</td>\n",
       "      <td>5.686388</td>\n",
       "      <td>17.623555</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>184.91670</td>\n",
       "      <td>5886</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>expected_time_buy</th>\n",
       "      <td>52257.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>348</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>expected_time_visit</th>\n",
       "      <td>52257.0</td>\n",
       "      <td>-9.669298</td>\n",
       "      <td>31.239030</td>\n",
       "      <td>-187.6156</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>91.40192</td>\n",
       "      <td>15135</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last_buy</th>\n",
       "      <td>52257.0</td>\n",
       "      <td>65.741317</td>\n",
       "      <td>53.484622</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>19.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>106.000000</td>\n",
       "      <td>188.00000</td>\n",
       "      <td>189</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last_visit</th>\n",
       "      <td>52257.0</td>\n",
       "      <td>65.741317</td>\n",
       "      <td>53.484622</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>19.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>106.000000</td>\n",
       "      <td>188.00000</td>\n",
       "      <td>189</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>multiple_buy</th>\n",
       "      <td>52257.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>multiple_visit</th>\n",
       "      <td>52257.0</td>\n",
       "      <td>0.255602</td>\n",
       "      <td>0.436203</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uniq_urls</th>\n",
       "      <td>52257.0</td>\n",
       "      <td>86.656180</td>\n",
       "      <td>61.996711</td>\n",
       "      <td>-1.0000</td>\n",
       "      <td>30.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>155.000000</td>\n",
       "      <td>206.00000</td>\n",
       "      <td>207</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_checkins</th>\n",
       "      <td>52257.0</td>\n",
       "      <td>721.848518</td>\n",
       "      <td>1284.504018</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>126.0</td>\n",
       "      <td>318.0</td>\n",
       "      <td>803.000000</td>\n",
       "      <td>37091.00000</td>\n",
       "      <td>4628</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y_buy</th>\n",
       "      <td>52257.0</td>\n",
       "      <td>0.003024</td>\n",
       "      <td>0.054904</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       count        mean          std       min    25%    50%  \\\n",
       "isbuyer              52257.0    0.000000     0.000000    0.0000    0.0    0.0   \n",
       "buy_freq                 0.0         NaN          NaN       NaN    NaN    NaN   \n",
       "visit_freq           52257.0    1.651549     2.147955    1.0000    1.0    1.0   \n",
       "buy_interval         52257.0    0.000000     0.000000    0.0000    0.0    0.0   \n",
       "sv_interval          52257.0    5.686388    17.623555    0.0000    0.0    0.0   \n",
       "expected_time_buy    52257.0    0.000000     0.000000    0.0000    0.0    0.0   \n",
       "expected_time_visit  52257.0   -9.669298    31.239030 -187.6156    0.0    0.0   \n",
       "last_buy             52257.0   65.741317    53.484622    0.0000   19.0   52.0   \n",
       "last_visit           52257.0   65.741317    53.484622    0.0000   19.0   52.0   \n",
       "multiple_buy         52257.0    0.000000     0.000000    0.0000    0.0    0.0   \n",
       "multiple_visit       52257.0    0.255602     0.436203    0.0000    0.0    0.0   \n",
       "uniq_urls            52257.0   86.656180    61.996711   -1.0000   30.0   75.0   \n",
       "num_checkins         52257.0  721.848518  1284.504018    1.0000  126.0  318.0   \n",
       "y_buy                52257.0    0.003024     0.054904    0.0000    0.0    0.0   \n",
       "\n",
       "                            75%          max  number_distinct  number_nan  \n",
       "isbuyer                0.000000      0.00000                2           0  \n",
       "buy_freq                    NaN          NaN               10       52257  \n",
       "visit_freq             2.000000     84.00000               64           0  \n",
       "buy_interval           0.000000      0.00000              295           0  \n",
       "sv_interval            0.041667    184.91670             5886           0  \n",
       "expected_time_buy      0.000000      0.00000              348           0  \n",
       "expected_time_visit    0.000000     91.40192            15135           0  \n",
       "last_buy             106.000000    188.00000              189           0  \n",
       "last_visit           106.000000    188.00000              189           0  \n",
       "multiple_buy           0.000000      0.00000                2           0  \n",
       "multiple_visit         1.000000      1.00000                2           0  \n",
       "uniq_urls            155.000000    206.00000              207           0  \n",
       "num_checkins         803.000000  37091.00000             4628           0  \n",
       "y_buy                  0.000000      1.00000                2           0  "
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "null_ads = ads[ads.isnull().any(axis=1)] \n",
    "getDfSummary(null_ads)\n",
    "# explanation is above "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6\\. (4 Points) Which variables are binary?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['isbuyer', 'multiple_buy', 'multiple_visit', 'y_buy'], dtype=object)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.loc[result['number_distinct'] == 2].index.values\n",
    "# Variables: isbuyer, multiple_buy, multiple_visit, y_buy are binary because they only have two distinct values"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
